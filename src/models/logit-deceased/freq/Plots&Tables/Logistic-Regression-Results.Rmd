---
title: ""
output: pdf_document
---

# TRAINING INDICES;  

```{r echo = FALSE, results = 'hide', message = FALSE, results = 'asis'}
require(tidyverse);
require(kableExtra);

training_indices <- readRDS("~/TABASCO-MEXCOV-19/src/models/logit-deceased/freq/5-fold_Cross_Validation/training_indices.rds");
for(i in 1:6)
{
  tmp = training_indices[[i]][9, 1];  training_indices[[i]][9, 1]  = training_indices[[i]][8, 1];  training_indices[[i]][8, 1]  = tmp;
  tmp = training_indices[[i]][9, 3];  training_indices[[i]][9, 3]  = training_indices[[i]][8, 3];  training_indices[[i]][8, 3]  = tmp;
  tmp = training_indices[[i]][9, 4];  training_indices[[i]][9, 4]  = training_indices[[i]][8, 4];  training_indices[[i]][8, 4]  = tmp;
  tmp = training_indices[[i]][11, 4]; training_indices[[i]][11, 4] = training_indices[[i]][10, 4]; training_indices[[i]][10, 4] = tmp;
}

tmp <-   data.frame( Predictors = c(    "+ EDAD",       "+ DIABETES",
                                        "+ SEXO",  "+ RENAL_CRONICA",
                                    "+ OBESIDAD",   "+ HIPERTENSION",
                                    "+ INMUSUPR",           "+ EPOC",
                                        "+ ASMA", "+ CARDIOVASCULAR",
                                                      "+ TABAQUISMO"),
                       Deviance = apply(X = training_indices$DEVIANCE, MARGIN = 1, FUN = mean),
                "Deviance (SE)" = apply(X = training_indices$DEVIANCE, MARGIN = 1, FUN = sd),
                            AIC = apply(X = training_indices$AIC,      MARGIN = 1, FUN = mean),
                     "AIC (SE)" = apply(X = training_indices$AIC,      MARGIN = 1, FUN = sd),
        "Likelihood Ratio Test" = apply(X = training_indices$LRT,      MARGIN = 1, FUN = mean),
   "Likelihood Ratio Test (SE)" = apply(X = training_indices$LRT,      MARGIN = 1, FUN = sd),
                    "Wald Test" = apply(X = training_indices$WALD,     MARGIN = 1, FUN = mean),
               "Wald Test (SE)" = apply(X = training_indices$WALD,     MARGIN = 1, FUN = sd));

tmp <- as.data.frame(tmp %>% mutate(round(tmp[, c(3, 5)], 2), round(tmp[, c(6:9)], 4)));
knitr::kable(tmp, row.names = FALSE, col.names = c("Predictors",
                                                   "Deviance",
                                                   "Deviance (SE)",
                                                   "AIC",
                                                   "AIC (SE)",
                                                   "LRT",
                                                   "LRT (SE)",
                                                   "Wald Test",
                                                   "Wald Test (SE)"),
             format = 'latex', booktabs = TRUE, align = c("r", rep('c', 8))) %>% kable_styling(position = "center", font_size = 8.5)
```  

# TRAIN & TEST ERRORS;  

```{r echo = TRUE, message = FALSE, fig.align = "center", fig.height = 7.5, fig.width = 10, fig.cap = "Train (orange) and test (blue) errors for model complexity as average of a 5-fold Cross Validation. The cutoff value is chosen to maximize both accuracy and sensitivity. Dashed lines represent min/max values of the cross validation runs. Top-Left: Cutoff values for model complexity. Top-Left: Accuracy values for model complexity. Bottom-Right: Sensitivity values for model complexity. Top-Right: Specificity values for model complexity."}
require(ggplot2);
require(gridExtra);

test_error  <- readRDS("~/TABASCO-MEXCOV-19/src/models/logit-deceased/freq/5-fold_Cross_Validation/test_error.rds");
train_error <- readRDS("~/TABASCO-MEXCOV-19/src/models/logit-deceased/freq/5-fold_Cross_Validation/train_error.rds");

# Complexity Vs (Cutoff, Accuracy, Sensitivity, Specificity) on TRAIN and TEST sets;
{
cut.plot <- ggplot() +
  
  # 5-fold CV Cutoff;
  geom_line(aes(x = c(1:11), y = apply(X = test_error$CUTOFF, MARGIN = 1, FUN = mean)),
            col = "#009dd0",
            size = 0.75) +
  geom_line(aes(x = c(1:11), y = apply(X = train_error$CUTOFF, MARGIN = 1, FUN = mean)),
            col = "#f58f3b",
            size = 0.75) +
  
  geom_ribbon(aes(x = c(1:11),
                  ymin = apply(X = test_error$CUTOFF, MARGIN = 1, FUN = min), 
                  ymax = apply(X = test_error$CUTOFF, MARGIN = 1, FUN = max)), 
              alpha    = 0.1,
              linetype = "dashed",
              colour   = "#009dd0",
              size     = 0.75,
              fill     = "#009dd0") +
  geom_ribbon(aes(x = c(1:11),
                  ymin = apply(X = train_error$CUTOFF, MARGIN = 1, FUN = min), 
                  ymax = apply(X = train_error$CUTOFF, MARGIN = 1, FUN = max)), 
              alpha    = 0.1,
              linetype = "dashed",
              colour   = "#f58f3b",
              size     = 0.75,
              fill     = "#f58f3b") +
  
  # Custom Labels;
  labs(title = "",
       subtitle = "",
       x = "Complexity",
       y = "Cutoff") +
  theme_bw(base_size = 17.5, base_family = "Times");

acc.plot <- ggplot() +
  
  # 5-fold CV Accuracy;
  geom_line(aes(x = c(1:11), y = apply(X = test_error$ACCURACY, MARGIN = 1, FUN = mean)),
            col = "#009dd0",
            size = 0.75) +
  geom_line(aes(x = c(1:11), y = apply(X = train_error$ACCURACY, MARGIN = 1, FUN = mean)),
            col = "#f58f3b",
            size = 0.75) +
  
  geom_ribbon(aes(x = c(1:11),
                  ymin = apply(X = test_error$ACCURACY, MARGIN = 1, FUN = min), 
                  ymax = apply(X = test_error$ACCURACY, MARGIN = 1, FUN = max)), 
              alpha    = 0.1,
              linetype = "dashed",
              colour   = "#009dd0",
              size     = 0.75,
              fill     = "#009dd0") +
  geom_ribbon(aes(x = c(1:11),
                  ymin = apply(X = train_error$ACCURACY, MARGIN = 1, FUN = min), 
                  ymax = apply(X = train_error$ACCURACY, MARGIN = 1, FUN = max)), 
              alpha    = 0.1,
              linetype = "dashed",
              colour   = "#f58f3b",
              size     = 0.75,
              fill     = "#f58f3b") +
  
  # Custom Labels;
  labs(title = "",
       subtitle = "",
       x = "Complexity",
       y = "Accuracy") +
  theme_bw(base_size = 17.5, base_family = "Times");

sen.plot <- ggplot() +
  
  # 5-fold CV Sensitivity;
  geom_line(aes(x = c(1:11), y = apply(X = test_error$SENSITIVITY, MARGIN = 1, FUN = mean)),
            col = "#009dd0",
            size = 0.75) +
  geom_line(aes(x = c(1:11), y = apply(X = train_error$SENSITIVITY, MARGIN = 1, FUN = mean)),
            col = "#f58f3b",
            size = 0.75) +
  
  geom_ribbon(aes(x = c(1:11),
                  ymin = apply(X = test_error$SENSITIVITY, MARGIN = 1, FUN = min), 
                  ymax = apply(X = test_error$SENSITIVITY, MARGIN = 1, FUN = max)), 
              alpha    = 0.1,
              linetype = "dashed",
              colour   = "#009dd0",
              size     = 0.75,
              fill     = "#009dd0") +
  geom_ribbon(aes(x = c(1:11),
                  ymin = apply(X = train_error$SENSITIVITY, MARGIN = 1, FUN = min), 
                  ymax = apply(X = train_error$SENSITIVITY, MARGIN = 1, FUN = max)), 
              alpha    = 0.1,
              linetype = "dashed",
              colour   = "#f58f3b",
              size     = 0.75,
              fill     = "#f58f3b") +
  
  # Custom Labels;
  labs(title = "",
       subtitle = "",
       x = "Complexity",
       y = "Sensitivity") +
  theme_bw(base_size = 17.5, base_family = "Times");

spe.plot <- ggplot() +
  
  # 5-fold CV Specificity;
  geom_line(aes(x = c(1:11), y = apply(X = test_error$SPECIFICITY, MARGIN = 1, FUN = mean)),
            col = "#009dd0",
            size = 0.75) +
  geom_line(aes(x = c(1:11), y = apply(X = train_error$SPECIFICITY, MARGIN = 1, FUN = mean)),
            col = "#f58f3b",
            size = 0.75) +
  
  geom_ribbon(aes(x = c(1:11),
                  ymin = apply(X = test_error$SPECIFICITY, MARGIN = 1, FUN = min), 
                  ymax = apply(X = test_error$SPECIFICITY, MARGIN = 1, FUN = max)), 
              alpha    = 0.1,
              linetype = "dashed",
              colour   = "#009dd0",
              size     = 0.75,
              fill     = "#009dd0") +
  geom_ribbon(aes(x = c(1:11),
                  ymin = apply(X = train_error$SPECIFICITY, MARGIN = 1, FUN = min), 
                  ymax = apply(X = train_error$SPECIFICITY, MARGIN = 1, FUN = max)), 
              alpha    = 0.1,
              linetype = "dashed",
              colour   = "#f58f3b",
              size     = 0.75,
              fill     = "#f58f3b") +
  
  # Custom Labels;
  labs(title = "",
       subtitle = "",
       x = "Complexity",
       y = "Specificty") +
  theme_bw(base_size = 17.5, base_family = "Times");

grid.arrange(cut.plot, acc.plot, sen.plot, spe.plot, nrow = 2); 
}
```  

# LOGISTIC REGRESSION SUMMARY;  

```{r echo = FALSE, results = 'hide', message = FALSE, results = 'asis'}
require(tidyverse);
require(kableExtra);

tmp <- read.table("~/TABASCO-MEXCOV-19/src/models/logit-deceased/freq/Plots&Tables/COEFFICIENTS.txt");
knitr::kable(tmp, row.names = TRUE, col.names = c("Estimates",
                                                  "Standard Error",
                                                  "2.5 (%)",
                                                  "97.5 (%)"),
             format = 'latex', booktabs = TRUE, align = c("r", rep('c', 8))) %>% kable_styling(position = "center", font_size = 8.5)
```  

# LOGISTIC REGRESSION RESULTS;  

```{r echo = FALSE, results = 'hide', message = FALSE, results = 'asis'}
require(tidyverse);
require(kableExtra);
require(caret);
options(knitr.kable.NA = '')

swabspos <- read.csv(gzfile("~/TABASCO-MEXCOV-19/data/cleansed/0718/swabspos_log_0718.csv.gz"));
glm.logit.fit     <- glm(FALLECIDO ~ ., family = binomial(link = "logit"), data = swabspos[, -c(5, 8, 11)], na.action = na.omit);
glm.logit.predict <- as.vector(predict(glm.logit.fit, newdata = swabspos, type = "response")); 
predicted.classes <- factor(ifelse(glm.logit.predict > 0.1610234, "Yes", "No"), levels = c("Yes", "No")); target <- factor(swabspos$FALLECIDO, levels = c("Yes", "No"));
tmp               <- confusionMatrix(data = predicted.classes, reference = target, positive = "Yes");

test_error  <- readRDS("~/TABASCO-MEXCOV-19/src/models/logit-deceased/freq/5-fold_Cross_Validation/test_error.rds");
train_error <- readRDS("~/TABASCO-MEXCOV-19/src/models/logit-deceased/freq/5-fold_Cross_Validation/train_error.rds");

dtf <- data.frame(" "                = c("Train", "Test"),
                  Accuracy           = c(mean(train_error$ACCURACY[8,]),    mean(test_error$ACCURACY[8,])),
                  "Accuracy (SE)"    = c(sd(train_error$ACCURACY[8,]),      sd(test_error$ACCURACY[8,])),
                  Sensitivity        = c(mean(train_error$SENSITIVITY[8,]), mean(test_error$SENSITIVITY[8,])),
                  "Sensitivity (SE)" = c(sd(train_error$SENSITIVITY[8,]),   sd(test_error$SENSITIVITY[8,])),
                  Specificity        = c(mean(train_error$SPECIFICITY[8,]), mean(test_error$SPECIFICITY[8,])),
                  "Specificity (SE)" = c(sd(train_error$SPECIFICITY[8,]),   sd(test_error$SPECIFICITY[8,])));
knitr::kable(dtf, row.names = FALSE, col.names = c(" ", "Accuracy", "Accuracy (SE)", "Sensitivity", "Sensitivity (SE)", "Specificity", "Specificity (SE)"), 
             format = 'latex', align = rep('c', 3), booktabs = T);
```  